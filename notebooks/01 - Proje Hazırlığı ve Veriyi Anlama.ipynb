{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gct1vH9c_C3O"
   },
   "source": [
    "# **Proje Hazƒ±rlƒ±ƒüƒ± ve Veriyi Anlama**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXAtgD05-vaw"
   },
   "source": [
    "## Dosya Yapƒ±sƒ± ƒ∞ncelemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2281,
     "status": "ok",
     "timestamp": 1764703753739,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "WQ2ejqEqYcNn",
    "outputId": "7078389d-6980-400a-c44c-a1051e48990b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dosya yolunu ayarla\n",
    "base_path = '/content/drive/MyDrive/Milano Telecom Data Analysis ‚Äî 2013 Week Dataset/archive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tArg9-zw_aiA"
   },
   "source": [
    "## Trafik Verisi ƒ∞ncelemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1764703753760,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "anIcGmEnZEh7",
    "outputId": "31c8a57d-a190-4537-d273-49ff256be848"
   },
   "outputs": [],
   "source": [
    "# 1. Trafik verisi √∂rneƒüi (ilk 100 satƒ±r)\n",
    "print(\"=== TRAFƒ∞K VERƒ∞Sƒ∞ ƒ∞NCELEMESƒ∞ ===\")\n",
    "traffic_file = base_path + 'sms-call-internet-mi-2013-11-01.csv'\n",
    "\n",
    "# S√ºtunlarƒ± g√∂r (√ßok b√ºy√ºk dosya, sadece header oku)\n",
    "try:\n",
    "    df_traffic_sample = pd.read_csv(traffic_file, nrows=100)\n",
    "    print(\"√ñrnek veri (100 satƒ±r):\")\n",
    "    print(df_traffic_sample.head())\n",
    "    print(\"\\nS√ºtunlar:\", df_traffic_sample.columns.tolist())\n",
    "    print(\"Boyut:\", df_traffic_sample.shape)\n",
    "\n",
    "    # Veri tipleri\n",
    "    print(\"\\nVeri tipleri:\")\n",
    "    print(df_traffic_sample.dtypes)\n",
    "\n",
    "    # Null deƒüerler\n",
    "    print(\"\\nNull deƒüer √∂zeti:\")\n",
    "    print(df_traffic_sample.isnull().sum())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Hata: {e}\")\n",
    "    # Alternatif: sadece ilk satƒ±rƒ± oku\n",
    "    with open(traffic_file, 'r') as f:\n",
    "        header = f.readline()\n",
    "    print(\"Header:\", header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu_D_MKV_pn1"
   },
   "source": [
    "## Hareket Verisi ƒ∞ncelemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1764703753808,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "kT8y-yXfZHOE",
    "outputId": "02a0e8c9-d802-4cd0-ec98-4c3138b21146"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== HAREKET VERƒ∞Sƒ∞ ƒ∞NCELEMESƒ∞ ===\")\n",
    "movement_file = base_path + 'mi-to-provinces-2013-11-01.csv'\n",
    "\n",
    "try:\n",
    "    df_movement_sample = pd.read_csv(movement_file, nrows=100)\n",
    "    print(\"√ñrnek veri (100 satƒ±r):\")\n",
    "    print(df_movement_sample.head())\n",
    "    print(\"\\nS√ºtunlar:\", df_movement_sample.columns.tolist())\n",
    "    print(\"Boyut:\", df_movement_sample.shape)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Hata: {e}\")\n",
    "    with open(movement_file, 'r') as f:\n",
    "        header = f.readline()\n",
    "    print(\"Header:\", header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUNNpVg9_v-F"
   },
   "source": [
    "## Census Verisi ƒ∞ncelemesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1764703753853,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "DZpchqzaZgrv",
    "outputId": "0c09fad5-85df-4e30-ea81-2842d592f299"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== CENSUS VERƒ∞Sƒ∞ ƒ∞NCELEMESƒ∞ ===\")\n",
    "census_file = base_path + 'ISTAT_census_variables_2011.csv'\n",
    "\n",
    "df_census = pd.read_csv(census_file)\n",
    "print(\"ƒ∞lk 5 satƒ±r:\")\n",
    "print(df_census.head())\n",
    "print(\"\\nS√ºtunlar:\", df_census.columns.tolist())\n",
    "print(\"Boyut:\", df_census.shape)\n",
    "print(\"\\nVeri tipleri:\")\n",
    "print(df_census.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6JZ9Vrm_230"
   },
   "source": [
    "## Geojson Dosyalarƒ±nƒ±n ƒ∞ncelenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1764703754501,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "LDWbOfh0Zokw",
    "outputId": "5761e696-89c3-4659-a498-308b7959116c"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== GEOJSON DOSYALARI ===\")\n",
    "# Milano grid\n",
    "with open(base_path + 'milano-grid.geojson', 'r') as f:\n",
    "    milano_grid = json.load(f)\n",
    "print(f\"Milano grid: {len(milano_grid['features'])} √∂zellik\")\n",
    "\n",
    "# ƒ∞talya eyaletleri\n",
    "with open(base_path + 'Italian_provinces.geojson', 'r') as f:\n",
    "    italian_provinces = json.load(f)\n",
    "print(f\"ƒ∞talyan eyaletleri: {len(italian_provinces['features'])} √∂zellik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFpq1d-zAAsx"
   },
   "source": [
    "## T√ºm Dosya Boyutlarƒ±nƒ±n Kontrol√º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1764703754525,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "GwX2L-GSZt5f",
    "outputId": "f694b05e-58bc-4657-b6da-811a546dfdc5"
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== T√úM DOSYA Lƒ∞STESƒ∞ VE BOYUTLARI ===\")\n",
    "import os\n",
    "\n",
    "# T√ºm CSV ve JSON dosyalarƒ±nƒ± bul\n",
    "all_files = []\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith(('.csv', '.json', '.geojson')):\n",
    "        all_files.append(file)\n",
    "\n",
    "# Alfabetik sƒ±rala\n",
    "all_files.sort()\n",
    "\n",
    "print(f\"Toplam {len(all_files)} dosya bulundu:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, file in enumerate(all_files, 1):\n",
    "    file_path = os.path.join(base_path, file)\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"{i:2d}. {file:45s} - {size_mb:8.2f} MB\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "total_size_mb = sum(os.path.getsize(os.path.join(base_path, f)) / (1024 * 1024) for f in all_files)\n",
    "print(f\"Toplam boyut: {total_size_mb:.2f} MB ({total_size_mb/1024:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGq6GUg-AqSI"
   },
   "source": [
    "# **BigQuery'ye Dosya Y√ºkleme Planƒ±**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcJrbRuWA6Ur"
   },
   "source": [
    "## Dosya Yolu ve Proje Bilgileri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1764706733862,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "YeJlp4Lmt4lP"
   },
   "outputs": [],
   "source": [
    "# Colab'da √ßalƒ±≈ütƒ±r\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "# Konfig√ºrasyon\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
    "DATASET_ID = \"milano_mobile_2013\"\n",
    "BASE_PATH = \"/content/drive/MyDrive/Milano Telecom Data Analysis ‚Äî 2013 Week Dataset/archive/\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLCJ8qmkBGxN"
   },
   "source": [
    "## Dataset Varlƒ±k Kontrol√º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1849,
     "status": "ok",
     "timestamp": 1764706742005,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "r44yX-8Et8i5",
    "outputId": "5df7ce85-7755-4b19-c1f5-cbfacbf1a932"
   },
   "outputs": [],
   "source": [
    "# Dataset var mƒ± kontrol et\n",
    "dataset_ref = client.dataset(DATASET_ID)\n",
    "try:\n",
    "    client.get_dataset(dataset_ref)\n",
    "    print(f\"‚úÖ Dataset bulundu: {DATASET_ID}\")\n",
    "except NotFound:\n",
    "    print(f\"‚ùå Dataset bulunamadƒ±: {DATASET_ID}\")\n",
    "    # Eƒüer yoksa olu≈ütur (manuel olu≈üturmu≈ütunuz, bu gerekmez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SF7jNP3BNaz"
   },
   "source": [
    "## Tablolarƒ±n Y√ºklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253110,
     "status": "ok",
     "timestamp": 1764709579059,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "02V2uAB43tDR",
    "outputId": "45078e47-b8c2-48ae-b5a6-76492952e0b8"
   },
   "outputs": [],
   "source": [
    "def load_all_tables():\n",
    "    \"\"\"T√ºm dosyalarƒ± BigQuery'e y√ºkler\"\"\"\n",
    "\n",
    "    # 1. CENSUS VERƒ∞Sƒ∞\n",
    "    print(\"üìä 1. Census verisi y√ºkleniyor...\")\n",
    "    census_path = BASE_PATH + \"ISTAT_census_variables_2011.csv\"\n",
    "    df_census = pd.read_csv(census_path)\n",
    "\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.census_data\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=True,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    )\n",
    "\n",
    "    job = client.load_table_from_dataframe(df_census, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"   ‚úÖ census_data: {client.get_table(table_id).num_rows:,} satƒ±r\")\n",
    "\n",
    "    # 2. TRAFƒ∞K VERƒ∞Sƒ∞ (7 g√ºn)\n",
    "    print(\"\\nüì∂ 2. Trafik verisi y√ºkleniyor (7 g√ºn)...\")\n",
    "    traffic_files = [\n",
    "        \"sms-call-internet-mi-2013-11-01.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-02.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-03.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-04.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-05.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-06.csv\",\n",
    "        \"sms-call-internet-mi-2013-11-07.csv\"\n",
    "    ]\n",
    "\n",
    "    for i, file in enumerate(traffic_files, 1):\n",
    "        print(f\"   üìÖ G√ºn {i}/7: {file}\")\n",
    "        file_path = BASE_PATH + file\n",
    "        date_str = file[-15:-4]  # \"2013-11-01\" formatƒ±\n",
    "\n",
    "        # CSV'yi oku\n",
    "        df_chunk = pd.read_csv(file_path)\n",
    "\n",
    "        # datetime s√ºtununu d√∂n√º≈üt√ºr\n",
    "        df_chunk['datetime'] = pd.to_datetime(df_chunk['datetime'])\n",
    "\n",
    "        # load_date ekle\n",
    "        df_chunk['load_date'] = pd.to_datetime(date_str).date()\n",
    "\n",
    "        # Tablo adƒ±: traffic_YYYYMMDD\n",
    "        table_name = f\"traffic_{date_str.replace('-', '')}\"\n",
    "        table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
    "\n",
    "        job = client.load_table_from_dataframe(df_chunk, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "        print(f\"     ‚úÖ {table_name}: {df_chunk.shape[0]:,} satƒ±r\")\n",
    "\n",
    "    # 3. HAREKET VERƒ∞Sƒ∞ (7 g√ºn)\n",
    "    print(\"\\nüó∫Ô∏è  3. Hareket verisi y√ºkleniyor (7 g√ºn)...\")\n",
    "    movement_files = [\n",
    "        \"mi-to-provinces-2013-11-01.csv\",\n",
    "        \"mi-to-provinces-2013-11-02.csv\",\n",
    "        \"mi-to-provinces-2013-11-03.csv\",\n",
    "        \"mi-to-provinces-2013-11-04.csv\",\n",
    "        \"mi-to-provinces-2013-11-05.csv\",\n",
    "        \"mi-to-provinces-2013-11-06.csv\",\n",
    "        \"mi-to-provinces-2013-11-07.csv\"\n",
    "    ]\n",
    "\n",
    "    for i, file in enumerate(movement_files, 1):\n",
    "        print(f\"   üìÖ G√ºn {i}/7: {file}\")\n",
    "        file_path = BASE_PATH + file\n",
    "        date_str = file[-15:-4]\n",
    "\n",
    "        df_chunk = pd.read_csv(file_path)\n",
    "        df_chunk['datetime'] = pd.to_datetime(df_chunk['datetime'])\n",
    "        df_chunk['load_date'] = pd.to_datetime(date_str).date()\n",
    "\n",
    "        table_name = f\"movement_{date_str.replace('-', '')}\"\n",
    "        table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
    "\n",
    "        job = client.load_table_from_dataframe(df_chunk, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "        print(f\"     ‚úÖ {table_name}: {df_chunk.shape[0]:,} satƒ±r\")\n",
    "\n",
    "    # 4. GEOJSON DOSYALARI (D√úZELTƒ∞LMƒ∞≈û)\n",
    "    print(\"\\nüó∫Ô∏è  4. Coƒürafi veriler y√ºkleniyor...\")\n",
    "\n",
    "    # Milano grid - DOƒûRU S√úTUN ƒ∞Sƒ∞MLERƒ∞YLE\n",
    "    print(\"   üìç Milano grid...\")\n",
    "    grid_path = BASE_PATH + \"milano-grid.geojson\"\n",
    "    grid_gdf = gpd.read_file(grid_path)\n",
    "\n",
    "    # 'cellId' s√ºtununu 'CellID' olarak standardize et\n",
    "    grid_gdf = grid_gdf.rename(columns={'cellId': 'CellID'})\n",
    "\n",
    "    # GeoJSON'dan DataFrame'e - sadece gerekli s√ºtunlar\n",
    "    grid_df = pd.DataFrame({\n",
    "        'CellID': grid_gdf['CellID'],\n",
    "        'geometry': grid_gdf.geometry.astype(str)\n",
    "    })\n",
    "\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.grid_locations\"\n",
    "    job = client.load_table_from_dataframe(grid_df, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"     ‚úÖ grid_locations: {grid_df.shape[0]:,} satƒ±r\")\n",
    "    print(f\"     üîç √ñrnek CellID'ler: {grid_df['CellID'].head().tolist()}\")\n",
    "\n",
    "    # ƒ∞talya eyaletleri - DOƒûRU S√úTUN ƒ∞Sƒ∞MLERƒ∞YLE\n",
    "    print(\"   üáÆüáπ ƒ∞talya eyaletleri...\")\n",
    "    provinces_path = BASE_PATH + \"Italian_provinces.geojson\"\n",
    "    provinces_gdf = gpd.read_file(provinces_path)\n",
    "\n",
    "    # 'PROVINCIA' s√ºtununu 'province_name' olarak standardize et\n",
    "    provinces_df = pd.DataFrame({\n",
    "        'province_name': provinces_gdf['PROVINCIA'],\n",
    "        'province_code': provinces_gdf['SIGLA'],  # SIGLA = kƒ±saltma (TO, MI vb.)\n",
    "        'shape_area': provinces_gdf['SHAPE_AREA'],\n",
    "        'geometry': provinces_gdf.geometry.astype(str)\n",
    "    })\n",
    "\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.province_boundaries\"\n",
    "    job = client.load_table_from_dataframe(provinces_df, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"     ‚úÖ province_boundaries: {provinces_df.shape[0]:,} satƒ±r\")\n",
    "    print(f\"     üîç √ñrnek eyaletler: {provinces_df['province_name'].head().tolist()}\")\n",
    "\n",
    "    print(\"\\nüéâ T√úM TABLOLAR BA≈ûARIYLA Y√úKLENDƒ∞!\")\n",
    "\n",
    "# Fonksiyonu √ßalƒ±≈ütƒ±r\n",
    "load_all_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI5L8RYFBhuK"
   },
   "source": [
    "## Birle≈üik Tablolar Olu≈üturma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67gubYjsBmrM"
   },
   "source": [
    "### *7 g√ºnl√ºk trafik ve hareket verisi i√ßin birle≈üik view'ler*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8513,
     "status": "ok",
     "timestamp": 1764709723631,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "D2BaJCER31rd",
    "outputId": "923cb575-9409-495b-8aaa-dbe4cee4860e"
   },
   "outputs": [],
   "source": [
    "def create_combined_views():\n",
    "    \"\"\"Birle≈üik view'lar olu≈ütur\"\"\"\n",
    "\n",
    "    # 1. T√úM TRAFƒ∞K VERƒ∞Sƒ∞ (7 g√ºn)\n",
    "    print(\"üîÑ T√ºm trafik view'ƒ± olu≈üturuluyor...\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.traffic_all_days` AS\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131101` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131102` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131103` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131104` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131105` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131106` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.traffic_20131107`\n",
    "    \"\"\"\n",
    "\n",
    "    client.query(query).result()\n",
    "    print(\"   ‚úÖ traffic_all_days view olu≈üturuldu\")\n",
    "\n",
    "    # 2. T√úM HAREKET VERƒ∞Sƒ∞ (7 g√ºn)\n",
    "    print(\"üîÑ T√ºm hareket view'ƒ± olu≈üturuluyor...\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.movement_all_days` AS\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131101` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131102` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131103` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131104` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131105` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131106` UNION ALL\n",
    "    SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.movement_20131107`\n",
    "    \"\"\"\n",
    "\n",
    "    client.query(query).result()\n",
    "    print(\"   ‚úÖ movement_all_days view olu≈üturuldu\")\n",
    "\n",
    "    # 3. G√úNL√úK √ñZET TABLOSU\n",
    "    print(\"üîÑ G√ºnl√ºk √∂zet view'ƒ± olu≈üturuluyor...\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.daily_summary` AS\n",
    "    SELECT\n",
    "        DATE(datetime) as date,\n",
    "        EXTRACT(HOUR FROM datetime) as hour,\n",
    "        COUNT(DISTINCT CellID) as unique_cells,\n",
    "        SUM(COALESCE(smsin, 0)) as total_smsin,\n",
    "        SUM(COALESCE(smsout, 0)) as total_smsout,\n",
    "        SUM(COALESCE(callin, 0)) as total_callin,\n",
    "        SUM(COALESCE(callout, 0)) as total_callout,\n",
    "        SUM(COALESCE(internet, 0)) as total_internet\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.traffic_all_days`\n",
    "    GROUP BY date, hour\n",
    "    ORDER BY date, hour\n",
    "    \"\"\"\n",
    "\n",
    "    client.query(query).result()\n",
    "    print(\"   ‚úÖ daily_summary view olu≈üturuldu\")\n",
    "\n",
    "    # 4. EYALET BAZLI HAREKET √ñZETƒ∞\n",
    "    print(\"üîÑ Eyalet hareket √∂zeti view'ƒ± olu≈üturuluyor...\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.province_movement_summary` AS\n",
    "    SELECT\n",
    "        DATE(datetime) as date,\n",
    "        provinceName,\n",
    "        SUM(COALESCE(cell2Province, 0)) as total_from_milano,\n",
    "        SUM(COALESCE(Province2cell, 0)) as total_to_milano,\n",
    "        COUNT(DISTINCT CellID) as unique_cells_connected\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.movement_all_days`\n",
    "    GROUP BY date, provinceName\n",
    "    ORDER BY date, total_from_milano DESC\n",
    "    \"\"\"\n",
    "\n",
    "    client.query(query).result()\n",
    "    print(\"   ‚úÖ province_movement_summary view olu≈üturuldu\")\n",
    "\n",
    "    print(\"\\nüéâ T√úM VIEW'LAR OLU≈ûTURULDU!\")\n",
    "\n",
    "# View'larƒ± olu≈ütur\n",
    "create_combined_views()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0wlY5OhCATj"
   },
   "source": [
    "## Doƒürulama Sorgularƒ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8798,
     "status": "ok",
     "timestamp": 1764709889009,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "NOSuGstW5hOb",
    "outputId": "83945083-6763-4877-e5df-3ff1b26bfdab"
   },
   "outputs": [],
   "source": [
    "def verify_tables():\n",
    "    \"\"\"Tablolarƒ± doƒürula\"\"\"\n",
    "\n",
    "    print(\"üîç TABLO DOƒûRULAMASI\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Dataset referansƒ±\n",
    "    dataset_ref = client.dataset(DATASET_ID)\n",
    "\n",
    "    table_info = []\n",
    "    try:\n",
    "        # Dataset'teki t√ºm tablolarƒ± listele\n",
    "        tables = list(client.list_tables(dataset_ref))\n",
    "\n",
    "        for table in tables:\n",
    "            # Tablo referansƒ±\n",
    "            table_ref = dataset_ref.table(table.table_id)\n",
    "            table_obj = client.get_table(table_ref)\n",
    "\n",
    "            table_info.append({\n",
    "                'Table': table.table_id,\n",
    "                'Rows': f\"{table_obj.num_rows:,}\",\n",
    "                'Size (MB)': f\"{table_obj.num_bytes / (1024*1024):.1f}\",\n",
    "                'Type': table_obj.table_type\n",
    "            })\n",
    "\n",
    "        # DataFrame olarak g√∂ster\n",
    "        df_info = pd.DataFrame(table_info)\n",
    "        print(df_info.to_string(index=False))\n",
    "\n",
    "        # Toplam istatistik\n",
    "        total_rows = sum([table_obj.num_rows for table in tables])\n",
    "        total_size_mb = sum([table_obj.num_bytes for table in tables]) / (1024*1024)\n",
    "\n",
    "        print(f\"\\nüìà TOPLAM: {len(tables)} tablo, {total_rows:,} satƒ±r, {total_size_mb:.1f} MB\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return None\n",
    "\n",
    "    return df_info\n",
    "\n",
    "# Doƒürulama √ßalƒ±≈ütƒ±r\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TABLO DOƒûRULAMA √áALI≈ûTIRILIYOR...\")\n",
    "print(\"=\"*50)\n",
    "df_tables = verify_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hPEXshqCJ3f"
   },
   "source": [
    "## **RELEASE THE KRAKEN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263875,
     "status": "ok",
     "timestamp": 1764710199515,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "RbHb09L358_3",
    "outputId": "c7293ae2-9758-4bee-b1af-d2762cc939f6"
   },
   "outputs": [],
   "source": [
    "# T√ºm i≈ülemi ba≈ülat\n",
    "print(\"üöÄ BIGQUERY VERƒ∞ Y√úKLEME BA≈ûLIYOR...\")\n",
    "print(f\"üìÇ Project: {PROJECT_ID}\")\n",
    "print(f\"üìÇ Dataset: {DATASET_ID}\")\n",
    "print(f\"üìÅ Path: {BASE_PATH}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # 1. T√ºm tablolarƒ± y√ºkle\n",
    "    print(\"\\nüì¶ 1. TABLO Y√úKLEME ƒ∞≈ûLEMƒ∞\")\n",
    "    print(\"-\" * 30)\n",
    "    load_all_tables()\n",
    "\n",
    "    print(\"\\n‚úÖ TABLO Y√úKLEME TAMAMLANDI\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 2. View'larƒ± olu≈ütur\n",
    "    print(\"\\nüîó 2. VIEW OLU≈ûTURMA ƒ∞≈ûLEMƒ∞\")\n",
    "    print(\"-\" * 30)\n",
    "    create_combined_views()\n",
    "\n",
    "    print(\"\\n‚úÖ VIEW OLU≈ûTURMA TAMAMLANDI\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 3. Doƒürulama\n",
    "    print(\"\\nüîç 3. DOƒûRULAMA ƒ∞≈ûLEMƒ∞\")\n",
    "    print(\"-\" * 30)\n",
    "    df_tables = verify_tables()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üéâ PROJE HAZIR! NATURE ANALƒ∞ZLERƒ∞NE BA≈ûLAYABƒ∞Lƒ∞RSƒ∞Nƒ∞Z.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Ek bilgiler\n",
    "    print(\"\\nüìä HAZIR TABLOLAR:\")\n",
    "    print(\"   1. traffic_all_days - T√ºm trafik verisi\")\n",
    "    print(\"   2. movement_all_days - T√ºm hareket verisi\")\n",
    "    print(\"   3. daily_summary - G√ºnl√ºk trafik √∂zeti\")\n",
    "    print(\"   4. province_movement_summary - Eyalet hareket √∂zeti\")\n",
    "    print(\"   5. census_data - Demografik veri\")\n",
    "    print(\"   6. grid_locations - Milano grid h√ºcreleri\")\n",
    "    print(\"   7. province_boundaries - ƒ∞talya eyalet sƒ±nƒ±rlarƒ±\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå HATA OLU≈ûTU: {e}\")\n",
    "    print(\"\\nHata detayƒ±:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyXSecc3DB_7"
   },
   "source": [
    " *  *BigQuery'de 21 tablo olu≈üturuldu ve veri y√ºklendi*\n",
    " *  *4 birle≈üik view olu≈üturuldu (traffic_all_days, movement_all_days,daily_summary, province_movement_summary)*\n",
    " *  *Nature metodolojisine tam uyumlu veri yapƒ±sƒ± kuruldu*\n",
    " *  *Ger√ßek veri seti olduƒüu ke≈üfedildi (sentetik deƒüil, Telefonica Milano 2013 verisi)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqNePhsxDg9T"
   },
   "source": [
    "# **Summarise : G√ºn 1 (02.12.2025 Salƒ±): PROJE HAZIRLIƒûI VE VERƒ∞Yƒ∞ ANLAMA - TAMAMLANDI**\n",
    "\n",
    "* ‚úì Makale ve veri seti incelemesi tamamlanacak\n",
    "* ‚úì Proje hedefleri netle≈ütirilecek\n",
    "* ‚úì √áalƒ±≈üma ortamƒ± kurulacak"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTuxQcluvdpi7CkZTk8I5/",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
