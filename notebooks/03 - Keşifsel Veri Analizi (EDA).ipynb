{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5731,
     "status": "ok",
     "timestamp": 1764798061117,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "gFi6y6q20JBO",
    "outputId": "1681798a-8d07-40df-dedf-bf10bc2b7fb8"
   },
   "outputs": [],
   "source": [
    "# ðŸ“… Nature Metodolojisi EDA\n",
    "# ðŸŽ¯ Nature makalesindeki analizleri Milano verisinde uygulama\n",
    "\n",
    "print(\"ðŸš€ NATURE METODOLOJÄ°SÄ° EDA BAÅžLIYOR...\")\n",
    "print(\"ðŸŽ¯ Hedef: Nature Figure 1-5 benzeri analizler\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. KÃ¼tÃ¼phaneleri yÃ¼kle\n",
    "!pip install -q google-cloud-bigquery pandas numpy matplotlib seaborn scipy geopandas\n",
    "print(\"âœ… KÃ¼tÃ¼phaneler yÃ¼klendi\")\n",
    "\n",
    "# 2. Authentication\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print(\"âœ… Authentication tamamlandÄ±\")\n",
    "\n",
    "# 3. Import'lar\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… TÃ¼m import'lar tamamlandÄ±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1764798065479,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "us-UBO_v0L22",
    "outputId": "4fe40cbc-970c-4ebd-ece0-1fee654c0acc"
   },
   "outputs": [],
   "source": [
    "# ðŸ“Œ HÃœCRE 2.1: TABLO SCHEMA KONTROLÃœ\n",
    "\n",
    "print(\"\\nðŸ” TABLO SCHEMA KONTROLLERÄ°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def check_table_schema_simple(table_name):\n",
    "    \"\"\"Tablonun schema'sÄ±nÄ± basit ÅŸekilde kontrol et\"\"\"\n",
    "    try:\n",
    "        # Tabloyu direkt okuyarak schema'yÄ± al\n",
    "        table_ref = client.dataset(DATASET_ID).table(table_name)\n",
    "        table = client.get_table(table_ref)\n",
    "\n",
    "        print(f\"\\nðŸ“‹ {table_name.upper()} SCHEMA:\")\n",
    "        print(f\"   ðŸ“Š {len(table.schema)} sÃ¼tun, {table.num_rows:,} satÄ±r, {table.num_bytes/(1024*1024):.1f} MB\")\n",
    "\n",
    "        # SÃ¼tun bilgilerini gÃ¶ster\n",
    "        schema_info = []\n",
    "        for field in table.schema:\n",
    "            schema_info.append({\n",
    "                'Column': field.name,\n",
    "                'Type': field.field_type,\n",
    "                'Mode': field.mode if hasattr(field, 'mode') else 'NULLABLE'\n",
    "            })\n",
    "\n",
    "        df_schema = pd.DataFrame(schema_info)\n",
    "        print(df_schema.to_string(index=False))\n",
    "\n",
    "        return df_schema\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  {table_name}: Schema kontrol edilemedi - {str(e)[:100]}\")\n",
    "        return None\n",
    "\n",
    "# Nature analizleri iÃ§in kritik tablolarÄ±n schema'larÄ±nÄ± kontrol et\n",
    "critical_tables = [\n",
    "    'cell_summary_nature',\n",
    "    'traffic_winsorized',\n",
    "    'movement_clean',\n",
    "    'census_data',\n",
    "    'temporal_pattern_nature'\n",
    "]\n",
    "\n",
    "schemas = {}\n",
    "print(\"\\nðŸ“Š TABLO SCHEMA Ã–ZETLERÄ°:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for table in critical_tables:\n",
    "    if table in df_tables['table_name'].values:\n",
    "        schemas[table] = check_table_schema_simple(table)\n",
    "\n",
    "# Nature metodolojisi iÃ§in gerekli sÃ¼tunlarÄ± kontrol et\n",
    "print(\"\\nðŸŽ¯ NATURE METODOLOJÄ°SÄ° GEREKSÄ°NÄ°MLERÄ° KONTROLÃœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nature_requirements = {\n",
    "    'cell_summary_nature': ['CellID', 'total_activity', 'total_smsin', 'total_internet'],\n",
    "    'traffic_winsorized': ['datetime', 'CellID', 'smsin_winsorized', 'internet_winsorized'],\n",
    "    'movement_clean': ['datetime', 'CellID', 'provinceName', 'cell2Province_clean'],\n",
    "    'census_data': ['PROVINCIA'],  # + diÄŸer 134 demografik deÄŸiÅŸken\n",
    "    'temporal_pattern_nature': ['hour_of_day', 'day_of_week', 'total_hourly_smsin', 'total_hourly_internet']\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ” NATURE ANALÄ°ZLERÄ° Ä°Ã‡Ä°N KRÄ°TÄ°K SÃœTUN KONTROLÃœ:\")\n",
    "all_requirements_met = True\n",
    "\n",
    "for table, required_cols in nature_requirements.items():\n",
    "    if table in schemas and schemas[table] is not None:\n",
    "        available_cols = schemas[table]['Column'].tolist()\n",
    "        missing_cols = [col for col in required_cols if col not in available_cols]\n",
    "\n",
    "        if missing_cols:\n",
    "            print(f\"   âš ï¸  {table}: {len(missing_cols)} eksik sÃ¼tun - {missing_cols}\")\n",
    "            all_requirements_met = False\n",
    "        else:\n",
    "            print(f\"   âœ… {table}: TÃ¼m {len(required_cols)} gerekli sÃ¼tun mevcut\")\n",
    "            print(f\"      ðŸ“Š Mevcut sÃ¼tunlar: {len(available_cols)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {table}: Schema kontrol edilemedi\")\n",
    "        all_requirements_met = False\n",
    "\n",
    "if all_requirements_met:\n",
    "    print(\"\\nðŸŽ‰ TEBRÄ°KLER! TÃ¼m Nature gereksinimleri karÅŸÄ±lanÄ±yor!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  UYARI: BazÄ± Nature gereksinimleri eksik\")\n",
    "\n",
    "# Nature'daki analizler iÃ§in Ã¶zel sÃ¼tun analizi\n",
    "print(\"\\nðŸ“Š NATURE ANALÄ°ZLERÄ° Ä°Ã‡Ä°N Ã–ZEL KONTROLLER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. TRAFÄ°K VERÄ°SÄ°: Nature'daki gibi zaman serisi analizi iÃ§in\n",
    "if 'traffic_winsorized' in schemas and schemas['traffic_winsorized'] is not None:\n",
    "    traffic_cols = schemas['traffic_winsorized']['Column'].tolist()\n",
    "    print(f\"\\nðŸ“± TRAFÄ°K VERÄ°SÄ° ANALÄ°ZÄ° (traffic_winsorized):\")\n",
    "    print(f\"   â° Zaman serisi: {'datetime' in traffic_cols}\")\n",
    "    print(f\"   ðŸ“ Mekansal: {'CellID' in traffic_cols}\")\n",
    "    print(f\"   ðŸ“Š Aktivite metrikleri:\")\n",
    "    activity_metrics = [col for col in traffic_cols if any(x in col.lower() for x in ['sms', 'call', 'internet'])]\n",
    "    for metric in activity_metrics:\n",
    "        print(f\"      â€¢ {metric}\")\n",
    "\n",
    "# 2. CENSUS VERÄ°SÄ°: Nature'daki poverty mapping iÃ§in\n",
    "if 'census_data' in schemas and schemas['census_data'] is not None:\n",
    "    census_cols = schemas['census_data']['Column'].tolist()\n",
    "    print(f\"\\nðŸ“Š DEMOGRAFÄ°K VERÄ° ANALÄ°ZÄ° (census_data):\")\n",
    "    print(f\"   ðŸ“ Eyalet ismi: {'PROVINCIA' in census_cols}\")\n",
    "\n",
    "    # Demografik deÄŸiÅŸken kategorileri\n",
    "    pop_vars = [c for c in census_cols if c.startswith('P')]\n",
    "    edu_vars = [c for c in census_cols if c.startswith('E')]\n",
    "    other_vars = [c for c in census_cols if c not in pop_vars + edu_vars + ['PROVINCIA']]\n",
    "\n",
    "    print(f\"   ðŸ‘¥ NÃ¼fus deÄŸiÅŸkenleri: {len(pop_vars)}\")\n",
    "    print(f\"   ðŸŽ“ EÄŸitim deÄŸiÅŸkenleri: {len(edu_vars)}\")\n",
    "    print(f\"   ðŸ“ˆ DiÄŸer deÄŸiÅŸkenler: {len(other_vars)}\")\n",
    "\n",
    "    # Ä°lk 5 Ã¶rnek\n",
    "    print(f\"   ðŸ” Ã–rnek nÃ¼fus deÄŸiÅŸkenleri: {pop_vars[:5]}\")\n",
    "    print(f\"   ðŸ” Ã–rnek eÄŸitim deÄŸiÅŸkenleri: {edu_vars[:5] if edu_vars else 'Yok'}\")\n",
    "\n",
    "# 3. HAREKET VERÄ°SÄ°: Nature'daki human mobility iÃ§in\n",
    "if 'movement_clean' in schemas and schemas['movement_clean'] is not None:\n",
    "    movement_cols = schemas['movement_clean']['Column'].tolist()\n",
    "    print(f\"\\nðŸ—ºï¸  HAREKET VERÄ°SÄ° ANALÄ°ZÄ° (movement_clean):\")\n",
    "    print(f\"   ðŸš¶ Hareket yÃ¶nÃ¼: {'cell2Province_clean' in movement_cols} (Milano'dan)\")\n",
    "    print(f\"   ðŸš¶ Hareket yÃ¶nÃ¼: {'Province2cell_clean' in movement_cols} (Milano'ya)\")\n",
    "    print(f\"   ðŸ“ Hedef lokasyon: {'provinceName' in movement_cols}\")\n",
    "    print(f\"   â° Zaman: {'datetime' in movement_cols}\")\n",
    "\n",
    "# 4. HÃœCRE Ã–ZETÄ°: Nature'daki anten Ã¶zeti iÃ§in\n",
    "if 'cell_summary_nature' in schemas and schemas['cell_summary_nature'] is not None:\n",
    "    cell_cols = schemas['cell_summary_nature']['Column'].tolist()\n",
    "    print(f\"\\nðŸ“¡ HÃœCRE Ã–ZET ANALÄ°ZÄ° (cell_summary_nature):\")\n",
    "    print(f\"   ðŸ“ HÃ¼cre ID: {'CellID' in cell_cols}\")\n",
    "    print(f\"   ðŸ“Š Toplam aktivite: {'total_activity' in cell_cols}\")\n",
    "\n",
    "    # Aktivite tÃ¼rleri\n",
    "    activity_cols = [c for c in cell_cols if 'total_' in c or 'avg_' in c]\n",
    "    print(f\"   ðŸ“ˆ Aktivite metrikleri: {len(activity_cols)}\")\n",
    "    for col in activity_cols[:5]:  # Ä°lk 5'ini gÃ¶ster\n",
    "        print(f\"      â€¢ {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… SCHEMA KONTROLLERÄ° TAMAMLANDI\")\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸŽ¯ Nature Figure 1-3 analizlerine geÃ§ebiliriz!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "executionInfo": {
     "elapsed": 3579,
     "status": "ok",
     "timestamp": 1764798077206,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "94tR9HG-0QFK",
    "outputId": "aead1dbd-9bb1-42dc-cfa3-48e341171103"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ™ï¸ NATURE FIGURE 1: ÅžEHÄ°R HÄ°YERARÅžÄ°SÄ° ANALÄ°ZÄ°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_nature_figure1():\n",
    "    \"\"\"Nature Figure 1: Power law distribution of traffic\"\"\"\n",
    "\n",
    "    # 1. Veriyi Ã§ek\n",
    "    query = f\"\"\"\n",
    "    WITH ranked_cells AS (\n",
    "      SELECT\n",
    "        total_activity,\n",
    "        ROW_NUMBER() OVER(ORDER BY total_activity DESC) as rank\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.cell_summary_nature`\n",
    "      WHERE total_activity > 0\n",
    "    )\n",
    "    SELECT\n",
    "      rank,\n",
    "      total_activity,\n",
    "      LOG(rank) as log_rank,\n",
    "      LOG(total_activity) as log_activity\n",
    "    FROM ranked_cells\n",
    "    ORDER BY rank\n",
    "    \"\"\"\n",
    "\n",
    "    df = client.query(query).to_dataframe()\n",
    "\n",
    "    # 2. Power law fitting (Nature'daki Î± parametresi)\n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        df['log_activity'], df['log_rank']\n",
    "    )\n",
    "    alpha = -slope  # Nature'daki Î± parametresi\n",
    "\n",
    "    # 3. Nature Figure 1 benzeri grafik\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Sol: Log-log plot (Nature Figure 1a)\n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(df['total_activity'], df['rank'], alpha=0.6, s=10)\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlabel('Total Activity (log scale)', fontsize=12)\n",
    "    ax1.set_ylabel('Rank (log scale)', fontsize=12)\n",
    "    ax1.set_title('Nature Figure 1a: Rank-Activity Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Trend Ã§izgisi ekle\n",
    "    x_fit = np.logspace(np.log10(df['total_activity'].min()),\n",
    "                       np.log10(df['total_activity'].max()), 100)\n",
    "    y_fit = 10**(intercept) * x_fit**(slope)\n",
    "    ax1.plot(x_fit, y_fit, 'r-', linewidth=2, label=f'Power law: Î±={alpha:.2f}')\n",
    "    ax1.legend()\n",
    "\n",
    "    # SaÄŸ: Histogram (Nature Figure 1b)\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(df['total_activity'], bins=50, log=True, alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_xlabel('Total Activity (log scale)', fontsize=12)\n",
    "    ax2.set_ylabel('Frequency (log scale)', fontsize=12)\n",
    "    ax2.set_title('Nature Figure 1b: Activity Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Ä°statistiksel sonuÃ§lar\n",
    "    print(\"ðŸ“Š POWER LAW ANALÄ°Z SONUÃ‡LARI:\")\n",
    "    print(f\"   ðŸ“ˆ Ã–rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼: {len(df):,} hÃ¼cre\")\n",
    "    print(f\"   ðŸŽ¯ Î± parametresi (Nature'da â‰ˆ 1.19): {alpha:.3f}\")\n",
    "    print(f\"   ðŸ“‰ Korelasyon katsayÄ±sÄ± (r): {r_value:.3f}\")\n",
    "    print(f\"   ðŸ“Š RÂ² deÄŸeri: {r_value**2:.3f}\")\n",
    "    print(f\"   ðŸ” p-deÄŸeri: {p_value:.4f}\")\n",
    "\n",
    "    # Nature ile karÅŸÄ±laÅŸtÄ±rma\n",
    "    nature_alpha = 1.19\n",
    "    similarity = 100 * (1 - abs(alpha - nature_alpha)/nature_alpha)\n",
    "\n",
    "    print(f\"\\nðŸ“š NATURE KARÅžILAÅžTIRMASI:\")\n",
    "    print(f\"   ðŸ“– Nature Î±: {nature_alpha}\")\n",
    "    print(f\"   ðŸ“Š Bizim Î±: {alpha:.3f}\")\n",
    "    print(f\"   ðŸ“ˆ Benzerlik: {similarity:.1f}%\")\n",
    "\n",
    "    return df, alpha\n",
    "\n",
    "# Ã‡alÄ±ÅŸtÄ±r\n",
    "df_figure1, alpha = plot_nature_figure1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1797,
     "status": "ok",
     "timestamp": 1764798083424,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "GY8gIrmB2ek-",
    "outputId": "e91b08ad-74be-4392-bc2c-6769520c9a6e"
   },
   "outputs": [],
   "source": [
    "# ðŸ“Œ HÃœCRE 4: NATURE FIGURE 2 - HAREKET MODELÄ° ANALÄ°ZÄ°\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš¶ NATURE FIGURE 2: Ä°NSAN HAREKETLÄ°LÄ°ÄžÄ° ANALÄ°ZÄ°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_nature_figure2():\n",
    "    \"\"\"Nature Figure 2: Human mobility patterns\"\"\"\n",
    "\n",
    "    # 1. Eyalet hareket verisini Ã§ek - POZÄ°TÄ°F DEÄžERLER FÄ°LTRELÄ°\n",
    "    query = f\"\"\"\n",
    "    WITH province_stats AS (\n",
    "      SELECT\n",
    "        p.province_name,\n",
    "        m.total_from_milano,\n",
    "        m.total_to_milano,\n",
    "        m.net_movement,\n",
    "        ST_DISTANCE(\n",
    "          ST_CENTROID(ST_GEOGFROMTEXT(p.geometry)),\n",
    "          (SELECT ST_CENTROID(ST_GEOGFROMTEXT(geometry))\n",
    "           FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries`\n",
    "           WHERE province_name = 'MILANO')\n",
    "        ) / 1000 as distance_km\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries` p\n",
    "      JOIN `{PROJECT_ID}.{DATASET_ID}.province_movement_nature` m\n",
    "        ON p.province_name = m.provinceName\n",
    "      WHERE p.province_name != 'MILANO'\n",
    "        AND m.total_from_milano > 0  -- POZÄ°TÄ°F HAREKET OLANLAR\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM province_stats\n",
    "    ORDER BY total_from_milano DESC\n",
    "    \"\"\"\n",
    "\n",
    "    df_movement = client.query(query).to_dataframe()\n",
    "\n",
    "    # 2. Pozitif deÄŸerleri kontrol et\n",
    "    print(f\"ðŸ“Š Hareket verisi: {len(df_movement)} eyalet\")\n",
    "    print(f\"   ðŸ” Pozitif hareket deÄŸerleri: {sum(df_movement['total_from_milano'] > 0)}\")\n",
    "    print(f\"   ðŸ“ Mesafe aralÄ±ÄŸÄ±: {df_movement['distance_km'].min():.1f} - {df_movement['distance_km'].max():.1f} km\")\n",
    "\n",
    "    # 3. Radyal daÄŸÄ±lÄ±m analizi (POZÄ°TÄ°F DEÄžERLER Ä°LE)\n",
    "    valid_data = df_movement[\n",
    "        (df_movement['distance_km'] > 0) &\n",
    "        (df_movement['total_from_milano'] > 0)\n",
    "    ].copy()\n",
    "\n",
    "    if len(valid_data) < 5:\n",
    "        print(\"âš ï¸  Yetersiz veri: En az 5 pozitif hareket kaydÄ± gerekli\")\n",
    "        return None, None\n",
    "\n",
    "    valid_data['log_distance'] = np.log(valid_data['distance_km'])\n",
    "    valid_data['log_movement'] = np.log(valid_data['total_from_milano'])\n",
    "\n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(\n",
    "        valid_data['log_distance'], valid_data['log_movement']\n",
    "    )\n",
    "    lambda_param = -slope  # Nature'daki Î» parametresi\n",
    "\n",
    "    # 4. Nature Figure 2 benzeri grafik\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Sol: Distance vs Movement (Nature Figure 2a) - LOG SCALE DÃœZELTMESÄ°\n",
    "    ax1 = axes[0]\n",
    "\n",
    "    # Pozitif deÄŸerleri filtrele\n",
    "    plot_data = valid_data.copy()\n",
    "\n",
    "    # Log scale iÃ§in minimum deÄŸer ayarla\n",
    "    min_movement = plot_data['total_from_milano'].min()\n",
    "    min_distance = plot_data['distance_km'].min()\n",
    "\n",
    "    scatter = ax1.scatter(plot_data['distance_km'], plot_data['total_from_milano'],\n",
    "                         alpha=0.7, s=80, c=plot_data['net_movement'], cmap='coolwarm',\n",
    "                         edgecolors='black', linewidth=0.5)\n",
    "\n",
    "    # Log scale uygula\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "\n",
    "    # Eksen limitlerini ayarla (0'dan bÃ¼yÃ¼k)\n",
    "    x_min = max(0.1, min_distance * 0.9)\n",
    "    x_max = plot_data['distance_km'].max() * 1.1\n",
    "    y_min = max(0.1, min_movement * 0.9)\n",
    "    y_max = plot_data['total_from_milano'].max() * 1.1\n",
    "\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_min, y_max)\n",
    "\n",
    "    ax1.set_xlabel('Distance from Milano (km, log scale)', fontsize=12)\n",
    "    ax1.set_ylabel('Movement Volume (log scale)', fontsize=12)\n",
    "    ax1.set_title('Nature Figure 2a: Distance-Movement Relationship', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Trend Ã§izgisi\n",
    "    x_fit = np.logspace(np.log10(x_min), np.log10(x_max), 100)\n",
    "    y_fit = np.exp(intercept) * x_fit**(slope)\n",
    "    ax1.plot(x_fit, y_fit, 'k--', linewidth=2, label=f'Î»={lambda_param:.2f}')\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.colorbar(scatter, ax=ax1, label='Net Movement')\n",
    "    ax1.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "    # SaÄŸ: Movement distribution (Nature Figure 2b)\n",
    "    ax2 = axes[1]\n",
    "    top_20 = df_movement.head(20)\n",
    "    colors = plt.cm.tab20c(np.arange(len(top_20)))\n",
    "    bars = ax2.barh(top_20['province_name'], top_20['total_from_milano'], color=colors)\n",
    "    ax2.set_xlabel('Movement Volume from Milano', fontsize=12)\n",
    "    ax2.set_title('Nature Figure 2b: Top 20 Destination Provinces', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "\n",
    "    # DeÄŸerleri ekle\n",
    "    for i, (bar, val) in enumerate(zip(bars, top_20['total_from_milano'])):\n",
    "        ax2.text(val + val*0.01, bar.get_y() + bar.get_height()/2,\n",
    "                f'{val:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Ä°statistiksel sonuÃ§lar\n",
    "    print(\"\\nðŸ“Š HAREKET ANALÄ°ZÄ° SONUÃ‡LARI:\")\n",
    "    print(f\"   ðŸ“ˆ Analiz edilen eyalet sayÄ±sÄ±: {len(valid_data)}\")\n",
    "    print(f\"   ðŸ“ Mesafe ortalamasÄ±: {valid_data['distance_km'].mean():.1f} km\")\n",
    "    print(f\"   ðŸš¶ Hareket ortalamasÄ±: {valid_data['total_from_milano'].mean():,.0f}\")\n",
    "    print(f\"   ðŸŽ¯ Î» parametresi (Nature'da â‰ˆ 2.06): {lambda_param:.3f}\")\n",
    "    print(f\"   ðŸ“‰ Korelasyon katsayÄ±sÄ±: {r_value:.3f}\")\n",
    "    print(f\"   ðŸ“Š RÂ² deÄŸeri: {r_value**2:.3f}\")\n",
    "    print(f\"   ðŸ” p-deÄŸeri: {p_value:.4f}\")\n",
    "\n",
    "    # Nature ile karÅŸÄ±laÅŸtÄ±rma\n",
    "    if not np.isnan(lambda_param):\n",
    "        nature_lambda = 2.06\n",
    "        similarity = 100 * (1 - abs(lambda_param - nature_lambda)/nature_lambda)\n",
    "\n",
    "        print(f\"\\nðŸ“š NATURE KARÅžILAÅžTIRMASI:\")\n",
    "        print(f\"   ðŸ“– Nature Î»: {nature_lambda}\")\n",
    "        print(f\"   ðŸ“Š Bizim Î»: {lambda_param:.3f}\")\n",
    "        print(f\"   ðŸ“ˆ Benzerlik: {similarity:.1f}%\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Î» parametresi hesaplanamadÄ±\")\n",
    "\n",
    "    return df_movement, lambda_param\n",
    "\n",
    "# Ã‡alÄ±ÅŸtÄ±r\n",
    "df_figure2, lambda_param = plot_nature_figure2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4800,
     "status": "ok",
     "timestamp": 1764798092103,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "_IWqGvo22k0o",
    "outputId": "8424ad84-bcef-4d3b-8c8d-e4001b6eafd5"
   },
   "outputs": [],
   "source": [
    "# ðŸ“Œ HÃœCRE 5: NATURE FIGURE 3 - EV-Ä°Åž KONUMU Ã‡IKARIMI\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ  NATURE FIGURE 3: EV-Ä°Åž KONUMU Ã‡IKARIMI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_nature_figure3():\n",
    "    \"\"\"Nature Figure 3: Home-work location inference\"\"\"\n",
    "\n",
    "    # 1. Zaman bazlÄ± trafik pattern'lerini Ã§ek\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "      hour_of_day,\n",
    "      day_of_week,\n",
    "      total_hourly_smsin,\n",
    "      total_hourly_internet,\n",
    "      total_hourly_calls,\n",
    "      active_cells,\n",
    "      avg_smsin_per_cell\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.temporal_pattern_nature`\n",
    "    ORDER BY day_of_week, hour_of_day\n",
    "    \"\"\"\n",
    "\n",
    "    df_temporal = client.query(query).to_dataframe()\n",
    "\n",
    "    # 2. Nature'daki gibi gece (20:00-08:00) ve gÃ¼ndÃ¼z (10:00-17:00) pattern'leri\n",
    "    df_temporal['period'] = 'other'\n",
    "    df_temporal.loc[df_temporal['hour_of_day'].between(20, 23) |\n",
    "                   df_temporal['hour_of_day'].between(0, 8), 'period'] = 'night'\n",
    "    df_temporal.loc[df_temporal['hour_of_day'].between(10, 17), 'period'] = 'day'\n",
    "\n",
    "    # 3. Nature Figure 3 benzeri grafik\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # 3.1 GÃ¼nlÃ¼k pattern (Nature Figure 3a)\n",
    "    weekday_data = df_temporal[df_temporal['day_of_week'].between(1, 5)]  # Pazartesi-Cuma\n",
    "    weekend_data = df_temporal[df_temporal['day_of_week'] >= 6]  # Cumartesi-Pazar\n",
    "\n",
    "    ax1 = axes[0, 0]\n",
    "    week_avg = weekday_data.groupby('hour_of_day')['total_hourly_smsin'].mean()\n",
    "    weekend_avg = weekend_data.groupby('hour_of_day')['total_hourly_smsin'].mean()\n",
    "\n",
    "    ax1.plot(week_avg.index, week_avg.values, 'b-', linewidth=2, label='Weekdays', marker='o')\n",
    "    ax1.plot(weekend_avg.index, weekend_avg.values, 'r-', linewidth=2, label='Weekend', marker='s')\n",
    "    ax1.set_xlabel('Hour of Day', fontsize=12)\n",
    "    ax1.set_ylabel('SMS Activity', fontsize=12)\n",
    "    ax1.set_title('Nature Figure 3a: Daily Activity Pattern', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.fill_between([20, 24], 0, ax1.get_ylim()[1], alpha=0.1, color='blue', label='Night (20-8)')\n",
    "    ax1.fill_between([10, 17], 0, ax1.get_ylim()[1], alpha=0.1, color='green', label='Day (10-17)')\n",
    "    ax1.legend()\n",
    "\n",
    "    # 3.2 HaftalÄ±k pattern (Nature Figure 3b)\n",
    "    ax2 = axes[0, 1]\n",
    "    daily_avg = df_temporal.groupby('day_of_week').agg({\n",
    "        'total_hourly_smsin': 'mean',\n",
    "        'total_hourly_internet': 'mean',\n",
    "        'total_hourly_calls': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    x_pos = np.arange(len(days))\n",
    "    width = 0.25\n",
    "\n",
    "    ax2.bar(x_pos - width, daily_avg['total_hourly_smsin'], width, label='SMS', alpha=0.8)\n",
    "    ax2.bar(x_pos, daily_avg['total_hourly_internet'], width, label='Internet', alpha=0.8)\n",
    "    ax2.bar(x_pos + width, daily_avg['total_hourly_calls'], width, label='Calls', alpha=0.8)\n",
    "\n",
    "    ax2.set_xlabel('Day of Week', fontsize=12)\n",
    "    ax2.set_ylabel('Average Hourly Activity', fontsize=12)\n",
    "    ax2.set_title('Nature Figure 3b: Weekly Activity Pattern', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(days)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # 3.3 Gece-gÃ¼ndÃ¼z aktivite oranÄ± (Nature'daki home-work inference)\n",
    "    ax3 = axes[1, 0]\n",
    "    period_ratio = df_temporal.groupby(['day_of_week', 'period'])['total_hourly_smsin'].mean().unstack()\n",
    "\n",
    "    # 'day' ve 'night' sÃ¼tunlarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et\n",
    "    if 'day' in period_ratio.columns and 'night' in period_ratio.columns:\n",
    "        period_ratio['day_night_ratio'] = period_ratio['day'] / period_ratio['night']\n",
    "\n",
    "        ax3.bar(range(1, 8), period_ratio['day_night_ratio'], color='purple', alpha=0.7)\n",
    "        ax3.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='Equal day/night')\n",
    "        ax3.set_xlabel('Day of Week', fontsize=12)\n",
    "        ax3.set_ylabel('Day/Night Activity Ratio', fontsize=12)\n",
    "        ax3.set_title('Nature Figure 3c: Home-Work Inference Metric', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xticks(range(1, 8))\n",
    "        ax3.set_xticklabels(days)\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'Day/Night verisi yetersiz',\n",
    "                ha='center', va='center', transform=ax3.transAxes, fontsize=12)\n",
    "        ax3.set_title('Nature Figure 3c: Home-Work Inference Metric\\n(Veri yetersiz)', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # 3.4 Aktivite Ã§eÅŸitliliÄŸi (Nature'daki activity diversity)\n",
    "    ax4 = axes[1, 1]\n",
    "    cell_query = f\"\"\"\n",
    "    SELECT\n",
    "      CellID,\n",
    "      total_smsin,\n",
    "      total_internet,\n",
    "      total_callin,\n",
    "      total_callout,\n",
    "      -- Toplam Ã§aÄŸrÄ± = gelen + giden\n",
    "      (total_callin + total_callout) as total_calls,\n",
    "      CASE\n",
    "        WHEN total_smsin > (total_callin + total_callout)\n",
    "             AND total_smsin > total_internet THEN 'SMS Dominant'\n",
    "        WHEN total_internet > (total_callin + total_callout)\n",
    "             AND total_internet > total_smsin THEN 'Internet Dominant'\n",
    "        WHEN (total_callin + total_callout) > total_smsin\n",
    "             AND (total_callin + total_callout) > total_internet THEN 'Call Dominant'\n",
    "        ELSE 'Balanced'\n",
    "      END as activity_type\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.cell_summary_nature`\n",
    "    \"\"\"\n",
    "\n",
    "    df_cell_types = client.query(cell_query).to_dataframe()\n",
    "    type_counts = df_cell_types['activity_type'].value_counts()\n",
    "\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "    wedges, texts, autotexts = ax4.pie(type_counts.values, labels=type_counts.index,\n",
    "                                       autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax4.set_title('Nature Figure 3d: Cell Activity Diversity', fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. Ä°statistiksel analiz\n",
    "    print(\"ðŸ“Š EV-Ä°Åž KONUMU ANALÄ°ZÄ° SONUÃ‡LARI:\")\n",
    "\n",
    "    # Period ratio analizi\n",
    "    if 'day' in period_ratio.columns and 'night' in period_ratio.columns:\n",
    "        print(f\"   â˜€ï¸  GÃ¼ndÃ¼z aktivite ortalamasÄ±: {period_ratio['day'].mean():.2f}\")\n",
    "        print(f\"   ðŸŒ™ Gece aktivite ortalamasÄ±: {period_ratio['night'].mean():.2f}\")\n",
    "        print(f\"   ðŸ“Š GÃ¼ndÃ¼z/Gece oranÄ±: {period_ratio['day_night_ratio'].mean():.2f}\")\n",
    "\n",
    "        # Nature'daki \"home-work location inference\" ile benzerlik\n",
    "        print(f\"\\nðŸ“š NATURE BENZERLÄ°ÄžÄ°:\")\n",
    "        print(\"   ðŸ” Nature'da gÃ¼ndÃ¼z aktivitesi iÅŸ yerlerini gÃ¶sterir\")\n",
    "        print(\"   ðŸ” Nature'da gece aktivitesi evleri gÃ¶sterir\")\n",
    "        print(\"   ðŸ“Š Bizim verimizde gÃ¼ndÃ¼z aktivitesi {:.1f}x daha fazla\".format(\n",
    "            period_ratio['day_night_ratio'].mean()))\n",
    "    else:\n",
    "        print(\"   âš ï¸  GÃ¼n/Gece analizi iÃ§in yeterli veri yok\")\n",
    "\n",
    "    # HÃ¼cre aktivite daÄŸÄ±lÄ±mÄ±\n",
    "    print(f\"\\nðŸ“± HÃœCRE AKTÄ°VÄ°TE DAÄžILIMI:\")\n",
    "    for activity_type, count in type_counts.items():\n",
    "        percentage = 100 * count / len(df_cell_types)\n",
    "        print(f\"   {activity_type}: {count:,} hÃ¼cre ({percentage:.1f}%)\")\n",
    "\n",
    "    # Zaman serisi Ã¶zeti\n",
    "    print(f\"\\nâ° ZAMANSAL PATTERN Ã–ZETÄ°:\")\n",
    "    print(f\"   ðŸ“… GÃ¶zlem sayÄ±sÄ±: {len(df_temporal)} (24 saat Ã— 7 gÃ¼n)\")\n",
    "    print(f\"   ðŸ“± Ortalama SMS aktivitesi: {df_temporal['total_hourly_smsin'].mean():.0f}\")\n",
    "    print(f\"   ðŸŒ Ortalama internet aktivitesi: {df_temporal['total_hourly_internet'].mean():.0f}\")\n",
    "    print(f\"   ðŸ“ž Ortalama Ã§aÄŸrÄ± aktivitesi: {df_temporal['total_hourly_calls'].mean():.0f}\")\n",
    "\n",
    "    return df_temporal, period_ratio if 'day_night_ratio' in period_ratio.columns else None, df_cell_types\n",
    "\n",
    "# Ã‡alÄ±ÅŸtÄ±r\n",
    "df_figure3, period_ratio, df_cell_types = plot_nature_figure3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4999,
     "status": "ok",
     "timestamp": 1764798102083,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "GZCE98U83kNq",
    "outputId": "654a95d4-c6c6-4bb7-9c70-b55c303cf33a"
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ” FIGURE 2 DEBUG: Ä°SÄ°M UYUÅžMAZLIÄžI KONTROLÃœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Hareket verisindeki eyalet isimlerini kontrol et\n",
    "query_mov = f\"\"\"\n",
    "SELECT DISTINCT provinceName\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.movement_clean`\n",
    "WHERE provinceName IS NOT NULL\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "print(\"ðŸ“‹ Movement Tablosundaki Ä°simler:\")\n",
    "df_mov_names = client.query(query_mov).to_dataframe()\n",
    "print(df_mov_names)\n",
    "\n",
    "# 2. SÄ±nÄ±r verisindeki eyalet isimlerini kontrol et\n",
    "query_bound = f\"\"\"\n",
    "SELECT DISTINCT province_name\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries`\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "print(\"\\nðŸ“‹ Boundaries Tablosundaki Ä°simler:\")\n",
    "df_bound_names = client.query(query_bound).to_dataframe()\n",
    "print(df_bound_names)\n",
    "\n",
    "# 3. Ã‡apraz kontrol (EÅŸleÅŸmeyenleri bul)\n",
    "query_check = f\"\"\"\n",
    "SELECT\n",
    "  m.provinceName as mov_name,\n",
    "  b.province_name as bound_name,\n",
    "  COUNT(*) as count\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.movement_clean` m\n",
    "LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.province_boundaries` b\n",
    "  ON UPPER(TRIM(m.provinceName)) = UPPER(TRIM(b.province_name))\n",
    "GROUP BY 1, 2\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "print(\"\\nâš ï¸ EÅŸleÅŸme KontrolÃ¼ (Sample):\")\n",
    "try:\n",
    "    df_check = client.query(query_check).to_dataframe()\n",
    "    print(df_check)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8002,
     "status": "ok",
     "timestamp": 1764798510054,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "AMhIqRblK1gJ",
    "outputId": "66a0e89c-49d1-433d-ba5b-2a143e05bff9"
   },
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneleri ve ayarlarÄ± tekrar tanÄ±mlayalÄ±m\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# BigQuery Client\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
    "DATASET_ID = \"milano_mobile_2013\"\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# ðŸ“‚ DOSYA YOLUNU TANIMLIYORUZ (HatanÄ±n sebebi burasÄ±ydÄ±)\n",
    "BASE_PATH = '/content/drive/MyDrive/Milano Telecom Data Analysis â€” 2013 Week Dataset/archive/'\n",
    "\n",
    "# EÄŸer klasÃ¶r bulunamazsa alternatifleri kontrol et (GÃ¼venlik Ã¶nlemi)\n",
    "if not os.path.exists(BASE_PATH):\n",
    "    print(\"âš ï¸ Standart yol bulunamadÄ±, alternatifler aranÄ±yor...\")\n",
    "    possible_paths = [\n",
    "        '/content/drive/MyDrive/Milano Telecom Data Analysis â€” 2013 Week Dataset/',\n",
    "        '/content/drive/MyDrive/archive/',\n",
    "        '/content/drive/MyDrive/'\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(os.path.join(path, \"Italian_provinces.geojson\")):\n",
    "            BASE_PATH = path\n",
    "            print(f\"âœ… Dosyalar ÅŸurada bulundu: {BASE_PATH}\")\n",
    "            break\n",
    "\n",
    "# GEOJSON KOORDÄ°NAT SÄ°STEMÄ° DÃœZELTME VE YENÄ°DEN YÃœKLEME\n",
    "def fix_and_reload_geojsons():\n",
    "    print(\"ðŸ”§ GEOJSON DÃœZELTME VE YÃœKLEME BAÅžLIYOR...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. Ä°TALYA EYALETLERÄ°\n",
    "    print(\"\\nðŸ‡®ðŸ‡¹ Ä°talya Eyaletleri (province_boundaries) dÃ¼zeltiliyor...\")\n",
    "    provinces_path = os.path.join(BASE_PATH, \"Italian_provinces.geojson\")\n",
    "\n",
    "    if os.path.exists(provinces_path):\n",
    "        try:\n",
    "            # DosyayÄ± oku\n",
    "            gdf_prov = gpd.read_file(provinces_path)\n",
    "            print(f\"   Orijinal CRS: {gdf_prov.crs}\")\n",
    "\n",
    "            # WGS84'e (EPSG:4326) dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "            if gdf_prov.crs != \"EPSG:4326\":\n",
    "                gdf_prov = gdf_prov.to_crs(\"EPSG:4326\")\n",
    "                print(f\"   âœ… EPSG:4326 (Lat/Lon) formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\")\n",
    "\n",
    "            # SÃ¼tun adlarÄ±nÄ± bul\n",
    "            name_col = next((col for col in ['PROVINCIA', 'name', 'NAME'] if col in gdf_prov.columns), None)\n",
    "\n",
    "            # DataFrame'e Ã§evir (WKT formatÄ±nda geometri ile)\n",
    "            df_prov = pd.DataFrame({\n",
    "                'province_name': gdf_prov[name_col] if name_col else gdf_prov.index.astype(str),\n",
    "                'geometry': gdf_prov.geometry.to_wkt()\n",
    "            })\n",
    "\n",
    "            # BigQuery'e YÃ¼kle\n",
    "            table_id = f\"{PROJECT_ID}.{DATASET_ID}.province_boundaries\"\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            )\n",
    "            job = client.load_table_from_dataframe(df_prov, table_id, job_config=job_config)\n",
    "            job.result()\n",
    "            print(f\"   âœ… province_boundaries yeniden yÃ¼klendi ({len(df_prov)} satÄ±r)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Hata: {e}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Dosya bulunamadÄ±: {provinces_path}\")\n",
    "\n",
    "    # 2. MILANO GRID\n",
    "    print(\"\\nðŸ“ Milano Grid (grid_locations) dÃ¼zeltiliyor...\")\n",
    "    grid_path = os.path.join(BASE_PATH, \"milano-grid.geojson\")\n",
    "\n",
    "    if os.path.exists(grid_path):\n",
    "        try:\n",
    "            gdf_grid = gpd.read_file(grid_path)\n",
    "            print(f\"   Orijinal CRS: {gdf_grid.crs}\")\n",
    "\n",
    "            if gdf_grid.crs != \"EPSG:4326\":\n",
    "                gdf_grid = gdf_grid.to_crs(\"EPSG:4326\")\n",
    "                print(f\"   âœ… EPSG:4326 (Lat/Lon) formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\")\n",
    "\n",
    "            # ID sÃ¼tununu bul\n",
    "            id_col = next((col for col in ['cellId', 'CellID', 'id'] if col in gdf_grid.columns), None)\n",
    "\n",
    "            df_grid = pd.DataFrame({\n",
    "                'CellID': gdf_grid[id_col] if id_col else range(1, len(gdf_grid)+1),\n",
    "                'geometry': gdf_grid.geometry.to_wkt()\n",
    "            })\n",
    "\n",
    "            table_id = f\"{PROJECT_ID}.{DATASET_ID}.grid_locations\"\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            )\n",
    "            job = client.load_table_from_dataframe(df_grid, table_id, job_config=job_config)\n",
    "            job.result()\n",
    "            print(f\"   âœ… grid_locations yeniden yÃ¼klendi ({len(df_grid)} satÄ±r)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Hata: {e}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Dosya bulunamadÄ±: {grid_path}\")\n",
    "\n",
    "# DÃ¼zeltme fonksiyonunu Ã§alÄ±ÅŸtÄ±r\n",
    "fix_and_reload_geojsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9099,
     "status": "ok",
     "timestamp": 1764798630362,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "aKkuxBeSJgVp",
    "outputId": "42dc2401-8f06-48fe-c68e-8b9956a72f62"
   },
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneleri tekrar import edelim (garanti olsun)\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import shapely.wkt\n",
    "\n",
    "# BigQuery Client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# GEOJSON ONARMA VE YÃœKLEME FONKSÄ°YONU\n",
    "def fix_and_reload_geojsons_v2():\n",
    "    print(\"ðŸ”§ GEOJSON GEOMETRÄ° ONARMA VE YÃœKLEME BAÅžLIYOR...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. Ä°TALYA EYALETLERÄ° (Province Boundaries)\n",
    "    print(\"\\nðŸ‡®ðŸ‡¹ Ä°talya Eyaletleri (province_boundaries) onarÄ±lÄ±yor...\")\n",
    "    provinces_path = os.path.join(BASE_PATH, \"Italian_provinces.geojson\")\n",
    "\n",
    "    if os.path.exists(provinces_path):\n",
    "        try:\n",
    "            # Okuma\n",
    "            gdf_prov = gpd.read_file(provinces_path)\n",
    "\n",
    "            # 1. CRS DÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
    "            if gdf_prov.crs != \"EPSG:4326\":\n",
    "                gdf_prov = gdf_prov.to_crs(\"EPSG:4326\")\n",
    "\n",
    "            # 2. KRÄ°TÄ°K DÃœZELTME: Geometriyi temizle (buffer(0))\n",
    "            # Bu iÅŸlem self-intersection ve duplicate vertex hatalarÄ±nÄ± dÃ¼zeltir\n",
    "            gdf_prov['geometry'] = gdf_prov['geometry'].buffer(0)\n",
    "            print(\"   âœ… Geometri topolojisi onarÄ±ldÄ± (buffer(0) uygulandÄ±)\")\n",
    "\n",
    "            # SÃ¼tun adÄ± belirleme\n",
    "            name_col = next((col for col in ['PROVINCIA', 'name', 'NAME'] if col in gdf_prov.columns), None)\n",
    "\n",
    "            # DataFrame hazÄ±rlÄ±ÄŸÄ±\n",
    "            df_prov = pd.DataFrame({\n",
    "                'province_name': gdf_prov[name_col] if name_col else gdf_prov.index.astype(str),\n",
    "                'geometry': gdf_prov.geometry.to_wkt()\n",
    "            })\n",
    "\n",
    "            # YÃ¼kleme\n",
    "            table_id = f\"{PROJECT_ID}.{DATASET_ID}.province_boundaries\"\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            )\n",
    "            job = client.load_table_from_dataframe(df_prov, table_id, job_config=job_config)\n",
    "            job.result()\n",
    "            print(f\"   âœ… province_boundaries baÅŸarÄ±yla yÃ¼klendi ({len(df_prov)} satÄ±r)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Hata: {e}\")\n",
    "\n",
    "    # 2. MILANO GRID (Grid Locations)\n",
    "    print(\"\\nðŸ“ Milano Grid (grid_locations) onarÄ±lÄ±yor...\")\n",
    "    grid_path = os.path.join(BASE_PATH, \"milano-grid.geojson\")\n",
    "\n",
    "    if os.path.exists(grid_path):\n",
    "        try:\n",
    "            # Okuma\n",
    "            gdf_grid = gpd.read_file(grid_path)\n",
    "\n",
    "            # 1. CRS DÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
    "            if gdf_grid.crs != \"EPSG:4326\":\n",
    "                gdf_grid = gdf_grid.to_crs(\"EPSG:4326\")\n",
    "\n",
    "            # 2. KRÄ°TÄ°K DÃœZELTME\n",
    "            gdf_grid['geometry'] = gdf_grid['geometry'].buffer(0)\n",
    "            print(\"   âœ… Geometri topolojisi onarÄ±ldÄ±\")\n",
    "\n",
    "            # ID sÃ¼tunu\n",
    "            id_col = next((col for col in ['cellId', 'CellID', 'id'] if col in gdf_grid.columns), None)\n",
    "\n",
    "            # DataFrame\n",
    "            df_grid = pd.DataFrame({\n",
    "                'CellID': gdf_grid[id_col] if id_col else range(1, len(gdf_grid)+1),\n",
    "                'geometry': gdf_grid.geometry.to_wkt()\n",
    "            })\n",
    "\n",
    "            # YÃ¼kleme\n",
    "            table_id = f\"{PROJECT_ID}.{DATASET_ID}.grid_locations\"\n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            )\n",
    "            job = client.load_table_from_dataframe(df_grid, table_id, job_config=job_config)\n",
    "            job.result()\n",
    "            print(f\"   âœ… grid_locations baÅŸarÄ±yla yÃ¼klendi ({len(df_grid)} satÄ±r)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Hata: {e}\")\n",
    "\n",
    "# Fonksiyonu Ã§alÄ±ÅŸtÄ±r\n",
    "fix_and_reload_geojsons_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "executionInfo": {
     "elapsed": 3894,
     "status": "ok",
     "timestamp": 1764798668497,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "LXOvtVbPJgoP",
    "outputId": "9630cf47-37b5-4c8d-d9e1-a3fc1cb2fffc"
   },
   "outputs": [],
   "source": [
    "def plot_nature_figure2_final():\n",
    "    \"\"\"Nature Figure 2: Human mobility patterns\"\"\"\n",
    "\n",
    "    print(\"\\nðŸš¶ NATURE FIGURE 2: Ä°NSAN HAREKETLÄ°LÄ°ÄžÄ° ANALÄ°ZÄ°\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # DÃœZELTME:\n",
    "    # 1. province_movement_nature tablosunda 'cell2Province_clean' yok, 'total_from_milano' var.\n",
    "    # 2. Gereksiz GROUP BY kaldÄ±rÄ±ldÄ± (tablo zaten gruplanmÄ±ÅŸ durumda).\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH province_stats AS (\n",
    "      SELECT\n",
    "        p.province_name,\n",
    "        m.total_from_milano,\n",
    "        ST_DISTANCE(\n",
    "          ST_CENTROID(ST_GEOGFROMTEXT(p.geometry)),\n",
    "          (SELECT ST_CENTROID(ST_GEOGFROMTEXT(geometry))\n",
    "           FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries`\n",
    "           WHERE UPPER(province_name) = 'MILANO')\n",
    "        ) / 1000 as distance_km\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries` p\n",
    "      JOIN `{PROJECT_ID}.{DATASET_ID}.province_movement_nature` m\n",
    "        -- Ä°SÄ°M EÅžLEÅžTÄ°RME (BÃ¼yÃ¼k/KÃ¼Ã§Ã¼k harf duyarsÄ±z):\n",
    "        ON UPPER(TRIM(p.province_name)) = UPPER(TRIM(m.provinceName))\n",
    "      WHERE UPPER(p.province_name) != 'MILANO'\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM province_stats\n",
    "    WHERE total_from_milano > 0 AND distance_km > 0\n",
    "    ORDER BY total_from_milano DESC\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_movement = client.query(query).to_dataframe()\n",
    "        print(f\"âœ… EÅŸleÅŸen ve verisi olan eyalet sayÄ±sÄ±: {len(df_movement)}\")\n",
    "\n",
    "        if len(df_movement) < 5:\n",
    "            print(\"âŒ Yetersiz veri. EÅŸleÅŸme veya veri sorunu devam ediyor.\")\n",
    "            print(\"   Debug: province_movement_nature tablosunu kontrol edin.\")\n",
    "            return None\n",
    "\n",
    "        # Ä°statistiksel Analiz (Power Law Fitting)\n",
    "        df_movement['log_distance'] = np.log(df_movement['distance_km'])\n",
    "        df_movement['log_movement'] = np.log(df_movement['total_from_milano'])\n",
    "\n",
    "        from scipy.stats import linregress\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(\n",
    "            df_movement['log_distance'], df_movement['log_movement']\n",
    "        )\n",
    "        lambda_param = -slope\n",
    "\n",
    "        print(f\"ðŸ“Š ANALÄ°Z SONUÃ‡LARI:\")\n",
    "        print(f\"   ðŸŽ¯ Î» parametresi (Nature â‰ˆ 2.06): {lambda_param:.3f}\")\n",
    "        print(f\"   ðŸ“‰ RÂ² deÄŸeri: {r_value**2:.3f}\")\n",
    "        print(f\"   ðŸ“ Ortalama Mesafe: {df_movement['distance_km'].mean():.1f} km\")\n",
    "\n",
    "        # GÃ¶rselleÅŸtirme\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # 1. Mesafe vs Hareket (Log-Log)\n",
    "        axes[0].scatter(df_movement['distance_km'], df_movement['total_from_milano'],\n",
    "                       alpha=0.6, s=80, c=df_movement['distance_km'], cmap='viridis')\n",
    "        axes[0].set_xscale('log')\n",
    "        axes[0].set_yscale('log')\n",
    "        axes[0].set_xlabel('Mesafe (km) [Log]', fontsize=12)\n",
    "        axes[0].set_ylabel('Hareket Hacmi [Log]', fontsize=12)\n",
    "        axes[0].set_title(f'Mesafe Bozunumu (Distance Decay)\\nÎ» = {lambda_param:.2f}', fontsize=14)\n",
    "\n",
    "        # Trend Ã§izgisi\n",
    "        x_vals = np.logspace(np.log10(df_movement['distance_km'].min()),\n",
    "                            np.log10(df_movement['distance_km'].max()), 100)\n",
    "        y_vals = np.exp(intercept) * x_vals**(slope)\n",
    "        axes[0].plot(x_vals, y_vals, 'r--', linewidth=2, label='Fit')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].legend()\n",
    "\n",
    "        # 2. En Ã‡ok EtkileÅŸim Olan Eyaletler\n",
    "        top_15 = df_movement.head(15)\n",
    "        sns.barplot(x='total_from_milano', y='province_name', data=top_15, ax=axes[1], palette='Blues_d')\n",
    "        axes[1].set_title('Milano ile En Ã‡ok EtkileÅŸen 15 Eyalet', fontsize=14)\n",
    "        axes[1].set_xlabel('Toplam Hareket', fontsize=12)\n",
    "        axes[1].set_ylabel('')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return df_movement\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Hata oluÅŸtu: {e}\")\n",
    "        return None\n",
    "\n",
    "# DÃ¼zeltilmiÅŸ analizi Ã§alÄ±ÅŸtÄ±r\n",
    "df_figure2 = plot_nature_figure2_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1764798911466,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "ySrBPCeAMo7F",
    "outputId": "ce6b6715-f991-4d4b-e74c-59b23a3293ba"
   },
   "outputs": [],
   "source": [
    "def plot_nature_figure4_network_revised(df_movement_data):\n",
    "    \"\"\"Nature Figure 4: Spatial Network Analysis (REVÄ°ZE EDÄ°LMÄ°Åž)\"\"\"\n",
    "    print(\"\\nðŸŒ NATURE FIGURE 4: MEKANSAL ETKÄ°LEÅžÄ°M AÄžI\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Veri KontrolÃ¼\n",
    "    if df_movement_data is None or df_movement_data.empty:\n",
    "        print(\"âŒ Hata: Figure 2 verisi boÅŸ. LÃ¼tfen Ã¶nce Figure 2'yi baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
    "        return\n",
    "\n",
    "    # Veri HazÄ±rlÄ±ÄŸÄ± (Sadece en gÃ¼Ã§lÃ¼ 50 baÄŸlantÄ±yÄ± alalÄ±m ki grafik karÄ±ÅŸmasÄ±n)\n",
    "    df_net = df_movement_data.head(50).copy()\n",
    "\n",
    "    # Graph OluÅŸturma\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Merkez DÃ¼ÄŸÃ¼m\n",
    "    center_node = \"MILANO\"\n",
    "    G.add_node(center_node, size=5000, color='red', label=center_node)\n",
    "\n",
    "    # Normalizasyon faktÃ¶rleri\n",
    "    max_flow = df_net['total_from_milano'].max()\n",
    "\n",
    "    print(f\"ðŸ“Š AÄŸ oluÅŸturuluyor... ({len(df_net)} baÄŸlantÄ±)\")\n",
    "\n",
    "    for _, row in df_net.iterrows():\n",
    "        province = row['province_name']\n",
    "        flow = row['total_from_milano']\n",
    "        dist = row['distance_km']\n",
    "\n",
    "        # DÃ¼ÄŸÃ¼m ekle (Boyut harekete gÃ¶re)\n",
    "        node_size = (flow / max_flow) * 3000 + 100\n",
    "        G.add_node(province, size=node_size, color='skyblue', label=province)\n",
    "\n",
    "        # Kenar ekle (AÄŸÄ±rlÄ±k harekete gÃ¶re, Uzunluk mesafeye gÃ¶re)\n",
    "        # NetworkX spring layout iÃ§in weight ne kadar bÃ¼yÃ¼kse o kadar yakÄ±n Ã§eker\n",
    "        weight = (flow / max_flow) * 10\n",
    "        G.add_edge(center_node, province, weight=weight, distance=dist)\n",
    "\n",
    "    # GÃ¶rselleÅŸtirme\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # YerleÅŸim (En Ã§ok etkileÅŸim olanlar merkeze yakÄ±n olsun)\n",
    "    pos = nx.spring_layout(G, k=0.3, iterations=50, weight='weight')\n",
    "\n",
    "    # DÃ¼ÄŸÃ¼mleri Ã§iz\n",
    "    node_sizes = [nx.get_node_attributes(G, 'size')[node] for node in G.nodes()]\n",
    "    node_colors = [nx.get_node_attributes(G, 'color')[node] for node in G.nodes()]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, alpha=0.9, edgecolors='black')\n",
    "\n",
    "    # KenarlarÄ± Ã§iz\n",
    "    edges = G.edges()\n",
    "    weights = [G[u][v]['weight'] for u,v in edges]\n",
    "    nx.draw_networkx_edges(G, pos, width=weights, alpha=0.3, edge_color='gray')\n",
    "\n",
    "    # Etiketleri Ã§iz (Sadece bÃ¼yÃ¼k dÃ¼ÄŸÃ¼mler iÃ§in)\n",
    "    labels = {}\n",
    "    for node in G.nodes():\n",
    "        if G.nodes[node]['size'] > 500 or node == center_node:\n",
    "            labels[node] = node\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=10, font_weight='bold')\n",
    "\n",
    "    plt.title(\"Milano Merkezli Hareketlilik AÄŸÄ± (Top 50 Ä°l)\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"âœ… AÄŸ analizi tamamlandÄ±.\")\n",
    "\n",
    "# Ã‡alÄ±ÅŸtÄ±rmak iÃ§in Figure 2 sonucunu kullanÄ±yoruz\n",
    "# df_figure2'nin tanÄ±mlÄ± olduÄŸundan emin olun\n",
    "if 'df_figure2' in locals():\n",
    "    plot_nature_figure4_network_revised(df_figure2)\n",
    "else:\n",
    "    print(\"âš ï¸ LÃ¼tfen Ã¶nce Figure 2 kodunu Ã§alÄ±ÅŸtÄ±rÄ±n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "executionInfo": {
     "elapsed": 3176,
     "status": "ok",
     "timestamp": 1764798933321,
     "user": {
      "displayName": "Emrah GÃ¶kpÄ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "udwc9wbOM_ii",
    "outputId": "97cbb143-6b7e-4162-a054-f6d16ebb3317"
   },
   "outputs": [],
   "source": [
    "def plot_nature_figure5_socioeconomic_revised():\n",
    "    \"\"\"Nature Figure 5: Socio-economic correlations (REVÄ°ZE EDÄ°LMÄ°Åž SQL)\"\"\"\n",
    "    print(\"\\nðŸ’° NATURE FIGURE 5: SOSYO-EKONOMÄ°K Ä°LÄ°ÅžKÄ°LER\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # DÃœZELTME NOTLARI:\n",
    "    # 1. census_data tablosunda 'PROVINCIA' sÃ¼tunu var.\n",
    "    # 2. province_movement_nature tablosunda 'provinceName' ve 'total_from_milano' var.\n",
    "    # 3. Ä°ki tabloyu UPPER ve TRIM ile eÅŸleÅŸtiriyoruz.\n",
    "\n",
    "    query = f\"\"\"\n",
    "    WITH census_agg AS (\n",
    "      SELECT\n",
    "        UPPER(TRIM(PROVINCIA)) as join_key,\n",
    "        PROVINCIA as original_name,\n",
    "        -- P1: Toplam NÃ¼fus (Genellikle Census verilerinde P1 nÃ¼fustur)\n",
    "        SUM(P1) as population,\n",
    "        -- E27: Toplam Ä°stihdam/Ekonomik Aktivite (VarsayÄ±lan)\n",
    "        SUM(E27) as economic_indicator\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.census_data`\n",
    "      GROUP BY 1, 2\n",
    "    ),\n",
    "    movement_agg AS (\n",
    "      SELECT\n",
    "        UPPER(TRIM(provinceName)) as join_key,\n",
    "        SUM(total_from_milano) as total_interaction\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.province_movement_nature`\n",
    "      GROUP BY 1\n",
    "    )\n",
    "    SELECT\n",
    "      c.original_name as province,\n",
    "      c.population,\n",
    "      c.economic_indicator,\n",
    "      m.total_interaction,\n",
    "      -- Gravity Index: (PopÃ¼lasyon * Hareket) / 1000\n",
    "      (c.population * m.total_interaction) / 1000000 as gravity_index\n",
    "    FROM census_agg c\n",
    "    JOIN movement_agg m ON c.join_key = m.join_key\n",
    "    WHERE c.population > 0 AND m.total_interaction > 0\n",
    "    ORDER BY c.population DESC\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_socio = client.query(query).to_dataframe()\n",
    "        print(f\"âœ… EÅŸleÅŸen Ä°l SayÄ±sÄ±: {len(df_socio)}\")\n",
    "\n",
    "        if len(df_socio) < 5:\n",
    "            print(\"âŒ Yetersiz veri eÅŸleÅŸmesi. Ä°sim formatlarÄ±nÄ± kontrol edin.\")\n",
    "            return\n",
    "\n",
    "        # Ä°statistiksel Analiz\n",
    "        # Hareket Hacmi ile NÃ¼fus arasÄ±ndaki korelasyon (Gravity Modelinin Temeli)\n",
    "        correlation = df_socio['population'].corr(df_socio['total_interaction'])\n",
    "\n",
    "        # GÃ¶rselleÅŸtirme\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # Grafik 1: NÃ¼fus vs EtkileÅŸim (Log-Log)\n",
    "        # Gravity modeline gÃ¶re nÃ¼fus arttÄ±kÃ§a etkileÅŸim artmalÄ±\n",
    "        axes[0].scatter(df_socio['population'], df_socio['total_interaction'],\n",
    "                       alpha=0.7, c='green', s=60, edgecolors='white')\n",
    "        axes[0].set_xscale('log')\n",
    "        axes[0].set_yscale('log')\n",
    "        axes[0].set_xlabel('Ä°l NÃ¼fusu (Log)', fontsize=12)\n",
    "        axes[0].set_ylabel('Milano ile EtkileÅŸim (Log)', fontsize=12)\n",
    "        axes[0].set_title(f'Gravity Model Testi\\nKorelasyon: {correlation:.2f}', fontsize=14)\n",
    "\n",
    "        # Trend Ã§izgisi\n",
    "        z = np.polyfit(np.log(df_socio['population']), np.log(df_socio['total_interaction']), 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_vals = np.linspace(df_socio['population'].min(), df_socio['population'].max(), 100)\n",
    "        axes[0].plot(x_vals, np.exp(p(np.log(x_vals))), \"r--\", linewidth=2, label='Trend')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Grafik 2: Ekonomik GÃ¶sterge vs EtkileÅŸim\n",
    "        # Ekonomik aktivite arttÄ±kÃ§a hareketlilik artÄ±yor mu?\n",
    "        axes[1].scatter(df_socio['economic_indicator'], df_socio['total_interaction'],\n",
    "                       alpha=0.7, c='purple', s=60, edgecolors='white')\n",
    "        axes[1].set_xscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "        axes[1].set_xlabel('Ekonomik Aktivite Ä°ndeksi (Log)', fontsize=12)\n",
    "        axes[1].set_ylabel('Milano ile EtkileÅŸim (Log)', fontsize=12)\n",
    "        axes[1].set_title('Ekonomik BaÄŸlÄ±lÄ±k Analizi', fontsize=14)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"ðŸ“Š SONUÃ‡LAR:\")\n",
    "        print(f\"   â€¢ NÃ¼fus-Hareket Korelasyonu: {correlation:.3f}\")\n",
    "        print(\"   â€¢ Yorum: NÃ¼fus bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ile Milano'dan gelen trafik arasÄ±nda gÃ¼Ã§lÃ¼ bir iliÅŸki beklenir.\")\n",
    "        print(\"     Bu, Nature makalesindeki sosyo-ekonomik tahmin modelini destekler.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Hata: {e}\")\n",
    "\n",
    "# Ã‡alÄ±ÅŸtÄ±r\n",
    "plot_nature_figure5_socioeconomic_revised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T49wuDLXNpwF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMVDxdUXXoou/WuqsqWZuK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
