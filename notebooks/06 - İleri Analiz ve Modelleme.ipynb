{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 47011,
     "status": "ok",
     "timestamp": 1765282821977,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "HWRpH9p7cZ3a",
    "outputId": "991eabc1-af19-4b98-a6c2-b56624721116"
   },
   "outputs": [],
   "source": [
    "# üìÖ ƒ∞leri Makine √ñƒürenmesi (Safe Mode)\n",
    "# üéØ Hedef: ≈ûehir b√∂lgelerinin trafik davranƒ±≈üƒ±nƒ± tahmin etmek (XGBoost)\n",
    "# üõ°Ô∏è Y√∂ntem: Ham veri yerine optimize edilmi≈ü 'dashboard_charts_hourly' tablosunu kullanƒ±r.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"üöÄ G√úVENLƒ∞ MODELLEME S√úRECƒ∞ BA≈ûLIYOR...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. KURULUM VE AUTH\n",
    "# ------------------------------------------------------------------------------\n",
    "!pip install google-cloud-bigquery pandas numpy matplotlib seaborn scikit-learn xgboost -q\n",
    "\n",
    "from google.colab import auth\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "auth.authenticate_user()\n",
    "print(\"‚úÖ Kimlik doƒürulama tamamlandƒ±.\")\n",
    "\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
    "DATASET_ID = \"milano_mobile_2013\"\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# 2. VERƒ∞ √áEKME (G√úVENLƒ∞ TABLO)\n",
    "# ------------------------------------------------------------------------------\n",
    "def fetch_safe_data():\n",
    "    print(\"\\nüìä VERƒ∞ √áEKƒ∞Lƒ∞YOR (dashboard_charts_hourly)...\")\n",
    "\n",
    "    # Sadece 0.03 MB veri okuyacak. Tamamen g√ºvenli.\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        datetime,\n",
    "        land_use_label as Cluster_Label, -- ƒ∞≈ü Merkezi, Konut vb.\n",
    "        total_activity\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.dashboard_charts_hourly`\n",
    "    WHERE land_use_label != 'Diƒüer' -- G√ºr√ºlt√ºy√º temizle\n",
    "    ORDER BY datetime\n",
    "    \"\"\"\n",
    "\n",
    "    df = client.query(query).to_dataframe()\n",
    "\n",
    "    # Feature Engineering (Python tarafƒ±nda yapƒ±yoruz, bedava i≈ülem)\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    # Lag Features (Ge√ßmi≈ü veriyi ekleme)\n",
    "    # Her b√∂lge tipi i√ßin ayrƒ± ayrƒ± kaydƒ±rma yapmalƒ±yƒ±z\n",
    "    df['prev_hour'] = df.groupby('Cluster_Label')['total_activity'].shift(1)\n",
    "    df['prev_24h'] = df.groupby('Cluster_Label')['total_activity'].shift(24)\n",
    "\n",
    "    df = df.dropna() # ƒ∞lk g√ºn√ºn verisi (ge√ßmi≈üi olmadƒ±ƒüƒ± i√ßin) silinir\n",
    "\n",
    "    print(f\"‚úÖ Veri Hazƒ±r: {len(df)} satƒ±r. (Maliyet: ~$0.00)\")\n",
    "    return df\n",
    "\n",
    "# 3. MODEL Eƒûƒ∞Tƒ∞Mƒ∞ (XGBOOST)\n",
    "# ------------------------------------------------------------------------------\n",
    "def train_models(df):\n",
    "    print(\"\\nü§ñ MODELLER Eƒûƒ∞Tƒ∞Lƒ∞YOR...\")\n",
    "\n",
    "    results_list = []\n",
    "    trained_models = {}\n",
    "\n",
    "    clusters = df['Cluster_Label'].unique()\n",
    "\n",
    "    # Grafik alanƒ± hazƒ±rla\n",
    "    fig, axes = plt.subplots(len(clusters), 1, figsize=(12, 4 * len(clusters)))\n",
    "    if len(clusters) == 1: axes = [axes]\n",
    "\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(f\"   üìç B√∂lge: {cluster} modelleniyor...\")\n",
    "\n",
    "        # O k√ºmeye ait veriyi al\n",
    "        data = df[df['Cluster_Label'] == cluster].copy()\n",
    "\n",
    "        # √ñzellikler ve Hedef\n",
    "        X = data[['hour', 'day_of_week', 'is_weekend', 'prev_hour', 'prev_24h']]\n",
    "        y = data['total_activity']\n",
    "\n",
    "        # Train/Test Split (Son %20'yi test i√ßin ayƒ±r - Zaman sƒ±rasƒ±na g√∂re)\n",
    "        split_idx = int(len(data) * 0.8)\n",
    "        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "        # Model\n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Tahmin\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Ba≈üarƒ± Metrikleri\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        results_list.append({\n",
    "            'B√∂lge': cluster,\n",
    "            'R2 Ba≈üarƒ± Skoru': f\"{r2:.4f}\",\n",
    "            'Ortalama Hata': f\"{mae:.2f}\"\n",
    "        })\n",
    "\n",
    "        # G√∂rselle≈ütirme\n",
    "        ax = axes[i]\n",
    "        ax.plot(y_test.values, label='Ger√ßek', color='blue', alpha=0.5)\n",
    "        ax.plot(y_pred, label='YZ Tahmini', color='red', linestyle='--', linewidth=2)\n",
    "        ax.set_title(f\"{cluster} - Tahmin Performansƒ± (R2: {r2:.2f})\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Tahminleri sakla (BigQuery'e atmak i√ßin)\n",
    "        data.loc[X_test.index, 'prediction'] = y_pred\n",
    "        trained_models[cluster] = data.loc[X_test.index]\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nüèÜ PERFORMANS SONU√áLARI:\")\n",
    "    print(pd.DataFrame(results_list))\n",
    "\n",
    "    return trained_models\n",
    "\n",
    "# 4. SONU√áLARI BIGQUERY'E KAYDETME\n",
    "# ------------------------------------------------------------------------------\n",
    "def save_results(models_dict):\n",
    "    print(\"\\nüíæ SONU√áLAR KAYDEDƒ∞Lƒ∞YOR...\")\n",
    "\n",
    "    # T√ºm tahminleri birle≈ütir\n",
    "    all_predictions = pd.concat(models_dict.values())\n",
    "\n",
    "    # Sadece gerekli s√ºtunlar\n",
    "    final_df = all_predictions[['datetime', 'Cluster_Label', 'total_activity', 'prediction']]\n",
    "    final_df.columns = ['datetime', 'zone_type', 'actual_value', 'predicted_value']\n",
    "\n",
    "    # BigQuery'e yaz\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.analysis_ml_predictions_v2\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "\n",
    "    job = client.load_table_from_dataframe(final_df, table_id, job_config=job_config)\n",
    "    job.result()\n",
    "\n",
    "    print(f\"‚úÖ Tahmin tablosu olu≈üturuldu: {table_id}\")\n",
    "    print(\"üëâ Looker Studio'da 'Ger√ßek vs Tahmin' grafiƒüi i√ßin bu tabloyu kullanabilirsiniz.\")\n",
    "\n",
    "# --- ANA AKI≈û ---\n",
    "df_safe = fetch_safe_data()\n",
    "if df_safe is not None:\n",
    "    prediction_results = train_models(df_safe)\n",
    "    save_results(prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1075,
     "status": "ok",
     "timestamp": 1765282839227,
     "user": {
      "displayName": "Emrah G√∂kpƒ±nar",
      "userId": "02372331561920614869"
     },
     "user_tz": -180
    },
    "id": "OEzzJ0yuDlPb",
    "outputId": "58680233-c2d4-44d4-e586-9d6c9c74f41c"
   },
   "outputs": [],
   "source": [
    "def create_fixed_connection_map_view():\n",
    "    print(\"\\nüó∫Ô∏è REPORTING: BAƒûLANTI HARƒ∞TASI (V2 - POINT-TO-POINT) OLU≈ûTURULUYOR...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Connection Map i√ßin Point 1 ve Point 2'yi \"Lat,Long\" string formatƒ±nda hazƒ±rlƒ±yoruz.\n",
    "    # Looker Studio bu formatƒ± \"Konum\" olarak √ßok sever.\n",
    "\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE VIEW `{PROJECT_ID}.{DATASET_ID}.reporting_connection_map_v2` AS\n",
    "    WITH milano_center AS (\n",
    "      SELECT\n",
    "        ST_CENTROID(ST_GEOGFROMTEXT(geometry)) as point\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries`\n",
    "      WHERE UPPER(province_name) = 'MILANO'\n",
    "    ),\n",
    "    province_centers AS (\n",
    "      SELECT\n",
    "        UPPER(TRIM(province_name)) as province_name,\n",
    "        ST_CENTROID(ST_GEOGFROMTEXT(geometry)) as point\n",
    "      FROM `{PROJECT_ID}.{DATASET_ID}.province_boundaries`\n",
    "    )\n",
    "    SELECT\n",
    "      m.provinceName as target_province,\n",
    "\n",
    "      -- Point 1: Origin (Milano) - GEOGRAPHY Tipi\n",
    "      (SELECT point FROM milano_center) as origin_geopoint,\n",
    "      -- Point 1: Origin (Milano) - STRING \"Lat,Long\" Tipi (Yedek Garantili)\n",
    "      CONCAT(CAST(ST_Y((SELECT point FROM milano_center)) AS STRING), ',', CAST(ST_X((SELECT point FROM milano_center)) AS STRING)) as origin_latlong,\n",
    "\n",
    "      -- Point 2: Destination (Hedef) - GEOGRAPHY Tipi\n",
    "      p.point as dest_geopoint,\n",
    "      -- Point 2: Destination (Hedef) - STRING \"Lat,Long\" Tipi (Yedek Garantili)\n",
    "      CONCAT(CAST(ST_Y(p.point) AS STRING), ',', CAST(ST_X(p.point) AS STRING)) as dest_latlong,\n",
    "\n",
    "      m.total_from_milano as flow_strength\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.province_movement_nature` m\n",
    "    JOIN province_centers p\n",
    "      ON UPPER(TRIM(m.provinceName)) = p.province_name\n",
    "    WHERE m.total_from_milano > 0\n",
    "      AND UPPER(m.provinceName) != 'MILANO'\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        client.query(query).result()\n",
    "        print(f\"‚úÖ View olu≈üturuldu: {PROJECT_ID}.{DATASET_ID}.reporting_connection_map_v2\")\n",
    "        print(\"üëâ Looker Studio'da 'reporting_connection_map_v2' tablosunu ekleyin.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Hata: {e}\")\n",
    "\n",
    "create_fixed_connection_map_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcqTdUhRDnWu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMWfZOya8esH4Yyoe/QVGaG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
